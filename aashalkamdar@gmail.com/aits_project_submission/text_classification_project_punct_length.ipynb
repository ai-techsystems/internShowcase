{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('smsspamcollection.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total number of entries in the dataset is 5572"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHecking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4825 ham messages out of a total 5527, which is approximately 87.3% . This means that any machine learning model we create has to perform better than 86.6% in order to beat random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is extremely skewed. The mean value is 80.5 and yet the max length is 910. Let's plot this on a logarithmic x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['length'],bins=bins,alpha=0.5)\n",
    "plt.hist(df[df['label']=='spam']['length'],bins=bins,alpha=0.5)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a small range of values where a message is more likely to be spam than ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean        4.177495\n",
       "std         4.623919\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         6.000000\n",
       "max       133.000000\n",
       "Name: punct, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['punct'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xscale('log')\n",
    "bins = 1.5**(np.arange(0,15))\n",
    "plt.hist(df[df['label']=='ham']['punct'],bins=bins,alpha=0.5)\n",
    "plt.hist(df[df['label']=='spam']['punct'],bins=bins,alpha=0.5)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks even worse - there seem to be no values where one would pick spam over ham. We'll still try to build a machine learning classification model, but we should expect poor results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we will perform classification the length and punctuation columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['length','punct']]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (3733, 2)\n",
      "Testing Data Shape:  (1839, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print('Training Data Shape:', X_train.shape)\n",
    "print('Testing Data Shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision, recall and f1 score is \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.92      1593\n",
      "        spam       0.10      0.02      0.03       246\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1839\n",
      "   macro avg       0.48      0.50      0.47      1839\n",
      "weighted avg       0.76      0.84      0.80      1839\n",
      "\n",
      "the accuracy is \n",
      "\n",
      "0.843936922240348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "lr_model = LogisticRegression(solver='lbfgs')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr_model.predict(X_test)\n",
    "\n",
    "print(\"the precision, recall and f1 score is \\n\")\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "print(\"the accuracy is \\n\")\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression performed worse than a classifier that assigned all messages as \"ham\" would have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision, recall and f1 score is \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.93      1593\n",
      "        spam       0.00      0.00      0.00       246\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1839\n",
      "   macro avg       0.43      0.50      0.46      1839\n",
      "weighted avg       0.75      0.86      0.80      1839\n",
      "\n",
      "the accuracy is \n",
      "\n",
      "0.8607939097335509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = nb_model.predict(X_test)\n",
    "\n",
    "print(\"the precision, recall and f1 score is \\n\")\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "print(\"the accuracy is \\n\")\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Better, but still less accurate than 86.6%</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision, recall and f1 score is \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.94      1593\n",
      "        spam       0.60      0.47      0.52       246\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1839\n",
      "   macro avg       0.76      0.71      0.73      1839\n",
      "weighted avg       0.88      0.89      0.88      1839\n",
      "\n",
      "the accuracy is \n",
      "\n",
      "0.8863512778684067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svc_model = SVC(gamma='auto')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = svc_model.predict(X_test)\n",
    "\n",
    "print(\"the precision, recall and f1 score is \\n\")\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "print(\"the accuracy is \\n\")\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC performs slightly better than random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision, recall and f1 score is \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.93      1593\n",
      "        spam       0.56      0.44      0.49       246\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1839\n",
      "   macro avg       0.74      0.69      0.71      1839\n",
      "weighted avg       0.87      0.88      0.87      1839\n",
      "\n",
      "the accuracy is \n",
      "\n",
      "0.878194671016857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(X_train, y_train)\n",
    "\n",
    "predictions = dec_tree.predict(X_test)\n",
    "\n",
    "print(\"the precision, recall and f1 score is \\n\")\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "print(\"the accuracy is \\n\")\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree also performs better than random guessing but SVC is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision, recall and f1 score is \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.93      1593\n",
      "        spam       0.59      0.48      0.53       246\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1839\n",
      "   macro avg       0.75      0.72      0.73      1839\n",
      "weighted avg       0.88      0.89      0.88      1839\n",
      "\n",
      "the accuracy is \n",
      "\n",
      "0.8852637302882002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=150)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test)\n",
    "\n",
    "print(\"the precision, recall and f1 score is \\n\")\n",
    "print(metrics.classification_report(y_test,predictions))\n",
    "print(\"the accuracy is \\n\")\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
