{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SycMb3Gsqdw4",
    "outputId": "1cae1fa8-7cb1-410d-c074-b2f6de1721c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OpCcKxiqixY"
   },
   "outputs": [],
   "source": [
    "#classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "aJcQKyAEPlyZ",
    "outputId": "54a01208-e6d0-44da-f0c7-25e15c56d07c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBdiYktDqvWy"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../content/drive/My Drive/titanic_data/train.csv')\n",
    "test = pd.read_csv('../content/drive/My Drive/titanic_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "colab_type": "code",
    "id": "-RHZxljOFDpG",
    "outputId": "aca8be5d-b6dc-42e4-926e-fe5ceaf2d540"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
       "0            1         0       3  ...   7.2500   NaN         S\n",
       "1            2         1       1  ...  71.2833   C85         C\n",
       "2            3         1       3  ...   7.9250   NaN         S\n",
       "3            4         1       1  ...  53.1000  C123         S\n",
       "4            5         0       3  ...   8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "dCfsFrokqyq9",
    "outputId": "0bc668bd-efdd-403e-a93b-1f18d127ab14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "6etThX3srNSa",
    "outputId": "ced94e4e-7c3b-44ad-d41f-b19fcdd1ada2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_columns = train.columns[train.isnull().any()]\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "66lWRV89rSc1",
    "outputId": "df8a0a51-a398-406e-e620-7f53ba63982c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
       "\n",
       "[8 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "Wp7DCpVk7amG",
    "outputId": "edbc4586-0271-45d7-cde7-46dbb36569b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "colab_type": "code",
    "id": "9YGnIX5271t1",
    "outputId": "1ffa2811-ac34-46e0-95dd-9f25d35d5131"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7faa10158550>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7faa100df588>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7faa10088b00>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7faa100390b8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7faa1005e630>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7faa10005ba8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7faa0ffb5160>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7faa0ffdb710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7faa0ffdb748>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGrCAYAAAD94/ynAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 648x504 with 9 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.hist(bins = 10, figsize = (9,7), grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "id": "d5zk0q6X98XF",
    "outputId": "63383575-2515-47c2-8871-2ca2358a0d76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faa0cbc0630>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAI1CAYAAADfHlAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQcqOfkPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "corr = train.corr()\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(corr, vmax =.8, linewidths = 0.01, square = True, annot = True, cmap='YlGnBu',linecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "VuqCF1Dy98gR",
    "outputId": "36c38de5-2479-4216-d8d0-a4cd243c83fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  ...  Fare Cabin  Embarked\n",
       "61            62         1       1  ...  80.0   B28       NaN\n",
       "829          830         1       1  ...  80.0   B28       NaN\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null columns for embarked\n",
    "\n",
    "train[train['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "_aySW8cE98ik",
    "outputId": "a88265b6-5148-4d93-83a0-226f4f112e9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faa0b656a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will check from where they are embarked\n",
    "sns.boxplot(x='Embarked', y='Fare', hue='Pclass', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQEuWr5X98k3"
   },
   "outputs": [],
   "source": [
    "# We can replace the value with 'C'\n",
    "\n",
    "train['Embarked'] = train['Embarked'].fillna('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "uTNEGp9YrVkL",
    "outputId": "afc847c9-6238-42ea-add3-eb95ac146e94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  ... Cabin       Lname  NamePrefix\n",
       "0            1         0       3  ...     N     Braund,         Mr.\n",
       "1            2         1       1  ...     C    Cumings,        Mrs.\n",
       "2            3         1       3  ...     N  Heikkinen,       Miss.\n",
       "3            4         1       1  ...     C   Futrelle,        Mrs.\n",
       "4            5         0       3  ...     N      Allen,         Mr.\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df\n",
    "  \n",
    "  \n",
    "\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df\n",
    "\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df    \n",
    "    \n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "train = transform_features(train)\n",
    "test = transform_features(test)\n",
    "train.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "eW3KXEF85V88",
    "outputId": "23ca73a3-fd70-4017-fd34-af3984cce866"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>401</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>843</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>552</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>851</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>342</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  NamePrefix\n",
       "0          892       3    1    7      0      0     0      7    401          19\n",
       "1          893       3    0    0      1      0     0      7    843          20\n",
       "2          894       2    1    3      0      0     1      7    552          19\n",
       "3          895       3    1    7      0      0     1      7    851          19\n",
       "4          896       3    0    4      1      1     1      7    342          20"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "w9-6WGI5B6VO",
    "outputId": "9bbe8af6-4794-4209-ea40-6727cc3b6ac9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  ...  Fare  Cabin  Lname  NamePrefix\n",
       "0            1         0       3    1  ...     0      7    100          19\n",
       "1            2         1       1    0  ...     3      2    182          20\n",
       "2            3         1       3    0  ...     0      7    329          16\n",
       "3            4         1       1    0  ...     3      2    267          20\n",
       "4            5         0       3    1  ...     1      7     15          19\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "    \n",
    "train, test = encode_features(train,test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "olIFoTlEr88t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OikCzNCFrXUF",
    "outputId": "0245860f-d0b7-4638-b922-f291ce35c15b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  NamePrefix\n",
      "681       1    1    7      0      0     3      3    320          19\n",
      "683       3    1    5      5      2     3      7    292          19\n",
      "249       2    1    0      1      0     2      7    131          26\n",
      "715       3    1    4      0      0     0      5    751          19\n",
      "175       3    1    5      1      1     0      7    413          19\n",
      "251       3    0    7      1      1     1      6    774          20\n",
      "279       3    0    7      1      1     2      7      1          20\n",
      "399       2    0    7      0      0     1      7    803          20\n",
      "638       3    0    0      0      5     3      7    609          20\n",
      "728       2    1    4      1      0     2      7    105          19\n",
      "612       3    0    6      1      0     2      7    550          16\n",
      "771       3    1    0      0      0     0      7    375          19\n",
      "356       1    0    4      0      1     3      4     94          16\n",
      "838       3    1    7      0      0     3      7    145          19\n",
      "564       3    0    6      0      0     1      7    514          16\n",
      "390       1    1    0      1      2     3      1    131          19\n",
      "635       2    0    7      0      0     1      7    196          16\n",
      "142       3    0    4      1      0     2      7    305          20\n",
      "700       1    0    5      1      0     3      2     37          20\n",
      "561       3    1    0      0      0     0      7    735          19\n",
      "440       2    0    0      1      1     2      7    319          20\n",
      "643       3    1    6      0      0     3      7    254          19\n",
      "5         3    1    6      0      0     1      7    538          19\n",
      "725       3    1    4      0      0     1      7    598          19\n",
      "822       1    1    0      0      0     4      7    660          10\n",
      "103       3    1    7      0      0     1      7    381          19\n",
      "487       1    1    0      0      0     2      1    403          19\n",
      "522       3    1    6      0      0     0      7    419          19\n",
      "267       3    1    4      1      0     0      7    632          19\n",
      "413       2    1    6      0      0     4      7    183          19\n",
      "..      ...  ...  ...    ...    ...   ...    ...    ...         ...\n",
      "72        2    1    4      0      0     3      7    352          19\n",
      "845       3    1    0      0      0     0      7      0          19\n",
      "537       1    0    7      0      0     3      7    431          16\n",
      "677       3    0    5      0      0     1      7    807          16\n",
      "849       1    0    6      1      0     3      2    288          20\n",
      "874       2    0    7      1      0     2      7      3          20\n",
      "174       1    1    0      0      0     2      0    747          19\n",
      "87        3    1    6      0      0     1      7    743          19\n",
      "551       2    1    7      0      0     2      7    718          19\n",
      "486       1    0    7      1      0     3      2    356          20\n",
      "705       2    1    0      0      0     2      7    540          19\n",
      "314       2    1    0      1      1     2      7    319          19\n",
      "396       3    0    7      0      0     0      7    595          16\n",
      "600       2    0    4      2      1     2      7    368          20\n",
      "472       2    0    7      1      2     2      7    833          20\n",
      "70        2    1    7      0      0     1      7    374          19\n",
      "599       1    1    0      1      0     3      0    224           8\n",
      "804       3    1    7      0      0     0      7    326          19\n",
      "754       2    0    0      1      2     3      7    335          20\n",
      "277       2    1    6      0      0     4      7    611          19\n",
      "723       2    1    0      0      0     1      7    344          19\n",
      "9         2    0    5      1      0     2      7    559          20\n",
      "359       3    0    6      0      0     0      7    532          16\n",
      "707       1    1    0      0      0     2      4    117          19\n",
      "763       1    0    0      1      2     3      1    131          20\n",
      "835       1    0    0      1      1     3      4    163          16\n",
      "192       3    0    4      1      0     0      7     19          16\n",
      "629       3    1    6      0      0     0      7    583          19\n",
      "559       3    0    0      1      0     2      7    865          15\n",
      "684       2    1    0      1      1     3      7    104          19\n",
      "\n",
      "[792 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y_all = train['Survived']\n",
    "\n",
    "num_test = 0.11\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=0)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Frb6yS1AsR-G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w0GQVIV6sXMP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4NFOpOXq6cTa",
    "outputId": "9205173f-2384-4141-8f8a-2044c9659564"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy score on the testing data:0.7980\n",
      "Final F-score on the testing data: 0.7796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "vector = SVC(random_state = 0)\n",
    "\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':(1,0.25,0.5,0.75),'gamma': (1,2,3,'auto'),'decision_function_shape':('ovo','ovr'),'shrinking':(True,False)}\n",
    "\n",
    "scorer = make_scorer(fbeta_score, beta = 0.5)\n",
    "\n",
    "grid_obj = GridSearchCV(vector, parameters, scoring = scorer)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# vector = vector.fit(X_train,y_train)\n",
    "\n",
    "#Get the estimator\n",
    "\n",
    "best_classifier = grid_fit.best_estimator_\n",
    "\n",
    "#Making predictions using this model\n",
    "\n",
    "best_predictions = best_classifier.predict(X_test)\n",
    "\n",
    "# Scores Report for SVM model for titanic dataset\n",
    "print('Final accuracy score on the testing data:{:.4f}'.format(accuracy_score(y_test,best_predictions)))\n",
    "print('Final F-score on the testing data: {:.4f}'.format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-1wEEgVoLRj"
   },
   "source": [
    "**Three- Neural Network in Pytorch**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vab5ow6P5wyF"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YMP1XC5R7cxl",
    "outputId": "d673ac87-c4b3-45eb-906f-eef846e20705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 792 samples, validate on 99 samples\n",
      "Epoch 1/100\n",
      "792/792 [==============================] - 3s 3ms/step - loss: 0.6736 - acc: 0.6035 - val_loss: 0.7051 - val_acc: 0.5758\n",
      "Epoch 2/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.6638 - acc: 0.6212 - val_loss: 0.6957 - val_acc: 0.5758\n",
      "Epoch 3/100\n",
      "792/792 [==============================] - 0s 59us/step - loss: 0.6620 - acc: 0.6212 - val_loss: 0.6910 - val_acc: 0.5758\n",
      "Epoch 4/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.6617 - acc: 0.6212 - val_loss: 0.7142 - val_acc: 0.5758\n",
      "Epoch 5/100\n",
      "792/792 [==============================] - 0s 59us/step - loss: 0.6611 - acc: 0.6212 - val_loss: 0.6882 - val_acc: 0.5758\n",
      "Epoch 6/100\n",
      "792/792 [==============================] - 0s 65us/step - loss: 0.6609 - acc: 0.6212 - val_loss: 0.6786 - val_acc: 0.5758\n",
      "Epoch 7/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.6547 - acc: 0.6212 - val_loss: 0.6893 - val_acc: 0.5758\n",
      "Epoch 8/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.6540 - acc: 0.6212 - val_loss: 0.6698 - val_acc: 0.5758\n",
      "Epoch 9/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.6500 - acc: 0.6212 - val_loss: 0.6634 - val_acc: 0.5758\n",
      "Epoch 10/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.6482 - acc: 0.6212 - val_loss: 0.6597 - val_acc: 0.5758\n",
      "Epoch 11/100\n",
      "792/792 [==============================] - 0s 65us/step - loss: 0.6438 - acc: 0.6212 - val_loss: 0.6504 - val_acc: 0.5758\n",
      "Epoch 12/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.6389 - acc: 0.6212 - val_loss: 0.6336 - val_acc: 0.5758\n",
      "Epoch 13/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.6337 - acc: 0.6212 - val_loss: 0.6340 - val_acc: 0.5758\n",
      "Epoch 14/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.6250 - acc: 0.6225 - val_loss: 0.6143 - val_acc: 0.5758\n",
      "Epoch 15/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.6181 - acc: 0.6402 - val_loss: 0.5963 - val_acc: 0.6465\n",
      "Epoch 16/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.6149 - acc: 0.6553 - val_loss: 0.6056 - val_acc: 0.7475\n",
      "Epoch 17/100\n",
      "792/792 [==============================] - 0s 68us/step - loss: 0.6054 - acc: 0.6780 - val_loss: 0.5811 - val_acc: 0.7172\n",
      "Epoch 18/100\n",
      "792/792 [==============================] - 0s 63us/step - loss: 0.5934 - acc: 0.7008 - val_loss: 0.5454 - val_acc: 0.7273\n",
      "Epoch 19/100\n",
      "792/792 [==============================] - 0s 63us/step - loss: 0.5988 - acc: 0.6944 - val_loss: 0.5435 - val_acc: 0.7879\n",
      "Epoch 20/100\n",
      "792/792 [==============================] - 0s 59us/step - loss: 0.5784 - acc: 0.7083 - val_loss: 0.5180 - val_acc: 0.7879\n",
      "Epoch 21/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.5611 - acc: 0.7172 - val_loss: 0.4867 - val_acc: 0.7879\n",
      "Epoch 22/100\n",
      "792/792 [==============================] - 0s 66us/step - loss: 0.5749 - acc: 0.7159 - val_loss: 0.5578 - val_acc: 0.6869\n",
      "Epoch 23/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.5516 - acc: 0.7285 - val_loss: 0.5015 - val_acc: 0.7778\n",
      "Epoch 24/100\n",
      "792/792 [==============================] - 0s 65us/step - loss: 0.5593 - acc: 0.7260 - val_loss: 0.4819 - val_acc: 0.8182\n",
      "Epoch 25/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.5721 - acc: 0.7159 - val_loss: 0.5166 - val_acc: 0.7576\n",
      "Epoch 26/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.5656 - acc: 0.7184 - val_loss: 0.6180 - val_acc: 0.6566\n",
      "Epoch 27/100\n",
      "792/792 [==============================] - 0s 63us/step - loss: 0.5425 - acc: 0.7336 - val_loss: 0.5106 - val_acc: 0.7172\n",
      "Epoch 28/100\n",
      "792/792 [==============================] - 0s 67us/step - loss: 0.5292 - acc: 0.7412 - val_loss: 0.4844 - val_acc: 0.7677\n",
      "Epoch 29/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.5162 - acc: 0.7513 - val_loss: 0.4965 - val_acc: 0.7576\n",
      "Epoch 30/100\n",
      "792/792 [==============================] - 0s 66us/step - loss: 0.5128 - acc: 0.7374 - val_loss: 0.4898 - val_acc: 0.7475\n",
      "Epoch 31/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4957 - acc: 0.7525 - val_loss: 0.4563 - val_acc: 0.8182\n",
      "Epoch 32/100\n",
      "792/792 [==============================] - 0s 65us/step - loss: 0.5051 - acc: 0.7551 - val_loss: 0.4792 - val_acc: 0.7576\n",
      "Epoch 33/100\n",
      "792/792 [==============================] - 0s 63us/step - loss: 0.4974 - acc: 0.7513 - val_loss: 0.4466 - val_acc: 0.7980\n",
      "Epoch 34/100\n",
      "792/792 [==============================] - 0s 65us/step - loss: 0.5735 - acc: 0.7323 - val_loss: 0.4831 - val_acc: 0.7677\n",
      "Epoch 35/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.5055 - acc: 0.7601 - val_loss: 0.4769 - val_acc: 0.7576\n",
      "Epoch 36/100\n",
      "792/792 [==============================] - 0s 69us/step - loss: 0.4986 - acc: 0.7652 - val_loss: 0.5518 - val_acc: 0.6970\n",
      "Epoch 37/100\n",
      "792/792 [==============================] - 0s 65us/step - loss: 0.5110 - acc: 0.7576 - val_loss: 0.4556 - val_acc: 0.7576\n",
      "Epoch 38/100\n",
      "792/792 [==============================] - 0s 67us/step - loss: 0.4858 - acc: 0.7639 - val_loss: 0.4285 - val_acc: 0.8283\n",
      "Epoch 39/100\n",
      "792/792 [==============================] - 0s 59us/step - loss: 0.5013 - acc: 0.7588 - val_loss: 0.4523 - val_acc: 0.8283\n",
      "Epoch 40/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.4916 - acc: 0.7639 - val_loss: 0.4384 - val_acc: 0.8485\n",
      "Epoch 41/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4794 - acc: 0.7753 - val_loss: 0.4341 - val_acc: 0.7778\n",
      "Epoch 42/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.5016 - acc: 0.7551 - val_loss: 0.4971 - val_acc: 0.7374\n",
      "Epoch 43/100\n",
      "792/792 [==============================] - 0s 67us/step - loss: 0.5166 - acc: 0.7500 - val_loss: 0.4873 - val_acc: 0.7475\n",
      "Epoch 44/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.5114 - acc: 0.7563 - val_loss: 0.4427 - val_acc: 0.7778\n",
      "Epoch 45/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4988 - acc: 0.7677 - val_loss: 0.4585 - val_acc: 0.8283\n",
      "Epoch 46/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.5119 - acc: 0.7449 - val_loss: 0.4327 - val_acc: 0.7778\n",
      "Epoch 47/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.4829 - acc: 0.7702 - val_loss: 0.4389 - val_acc: 0.7576\n",
      "Epoch 48/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.4790 - acc: 0.7740 - val_loss: 0.4249 - val_acc: 0.8384\n",
      "Epoch 49/100\n",
      "792/792 [==============================] - 0s 66us/step - loss: 0.4662 - acc: 0.7803 - val_loss: 0.4622 - val_acc: 0.7576\n",
      "Epoch 50/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.4718 - acc: 0.7740 - val_loss: 0.4262 - val_acc: 0.8384\n",
      "Epoch 51/100\n",
      "792/792 [==============================] - 0s 63us/step - loss: 0.4739 - acc: 0.7778 - val_loss: 0.4371 - val_acc: 0.8384\n",
      "Epoch 52/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.4708 - acc: 0.7753 - val_loss: 0.4422 - val_acc: 0.7576\n",
      "Epoch 53/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.4878 - acc: 0.7601 - val_loss: 0.5611 - val_acc: 0.7071\n",
      "Epoch 54/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4775 - acc: 0.7677 - val_loss: 0.5248 - val_acc: 0.7374\n",
      "Epoch 55/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4881 - acc: 0.7677 - val_loss: 0.4825 - val_acc: 0.8182\n",
      "Epoch 56/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.4635 - acc: 0.7753 - val_loss: 0.4215 - val_acc: 0.7879\n",
      "Epoch 57/100\n",
      "792/792 [==============================] - 0s 82us/step - loss: 0.4591 - acc: 0.7816 - val_loss: 0.4408 - val_acc: 0.7576\n",
      "Epoch 58/100\n",
      "792/792 [==============================] - 0s 58us/step - loss: 0.4730 - acc: 0.7765 - val_loss: 0.4165 - val_acc: 0.8182\n",
      "Epoch 59/100\n",
      "792/792 [==============================] - 0s 59us/step - loss: 0.4801 - acc: 0.7740 - val_loss: 0.4416 - val_acc: 0.8384\n",
      "Epoch 60/100\n",
      "792/792 [==============================] - 0s 59us/step - loss: 0.4679 - acc: 0.7740 - val_loss: 0.4236 - val_acc: 0.8182\n",
      "Epoch 61/100\n",
      "792/792 [==============================] - 0s 59us/step - loss: 0.4558 - acc: 0.7904 - val_loss: 0.4370 - val_acc: 0.7576\n",
      "Epoch 62/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.4595 - acc: 0.7929 - val_loss: 0.4519 - val_acc: 0.7576\n",
      "Epoch 63/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.4739 - acc: 0.7740 - val_loss: 0.5208 - val_acc: 0.7273\n",
      "Epoch 64/100\n",
      "792/792 [==============================] - 0s 67us/step - loss: 0.4653 - acc: 0.7765 - val_loss: 0.4516 - val_acc: 0.7475\n",
      "Epoch 65/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.4605 - acc: 0.7778 - val_loss: 0.4760 - val_acc: 0.7677\n",
      "Epoch 66/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.4695 - acc: 0.7664 - val_loss: 0.4126 - val_acc: 0.8182\n",
      "Epoch 67/100\n",
      "792/792 [==============================] - 0s 63us/step - loss: 0.4672 - acc: 0.7828 - val_loss: 0.4170 - val_acc: 0.8182\n",
      "Epoch 68/100\n",
      "792/792 [==============================] - 0s 66us/step - loss: 0.4589 - acc: 0.7740 - val_loss: 0.4151 - val_acc: 0.8182\n",
      "Epoch 69/100\n",
      "792/792 [==============================] - 0s 90us/step - loss: 0.4523 - acc: 0.7816 - val_loss: 0.4118 - val_acc: 0.8182\n",
      "Epoch 70/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4553 - acc: 0.7879 - val_loss: 0.4190 - val_acc: 0.8283\n",
      "Epoch 71/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.4606 - acc: 0.7778 - val_loss: 0.4112 - val_acc: 0.8182\n",
      "Epoch 72/100\n",
      "792/792 [==============================] - 0s 68us/step - loss: 0.4633 - acc: 0.7740 - val_loss: 0.4236 - val_acc: 0.8081\n",
      "Epoch 73/100\n",
      "792/792 [==============================] - 0s 63us/step - loss: 0.4503 - acc: 0.7828 - val_loss: 0.4018 - val_acc: 0.8081\n",
      "Epoch 74/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.4537 - acc: 0.7967 - val_loss: 0.4489 - val_acc: 0.7576\n",
      "Epoch 75/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4722 - acc: 0.7664 - val_loss: 0.5073 - val_acc: 0.7475\n",
      "Epoch 76/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.4744 - acc: 0.7715 - val_loss: 0.4770 - val_acc: 0.7576\n",
      "Epoch 77/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.4629 - acc: 0.7778 - val_loss: 0.3990 - val_acc: 0.8182\n",
      "Epoch 78/100\n",
      "792/792 [==============================] - 0s 68us/step - loss: 0.4524 - acc: 0.7917 - val_loss: 0.4008 - val_acc: 0.8182\n",
      "Epoch 79/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.5366 - acc: 0.7449 - val_loss: 0.5001 - val_acc: 0.8182\n",
      "Epoch 80/100\n",
      "792/792 [==============================] - 0s 58us/step - loss: 0.4901 - acc: 0.7689 - val_loss: 0.4115 - val_acc: 0.8182\n",
      "Epoch 81/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.4831 - acc: 0.7778 - val_loss: 0.5857 - val_acc: 0.6566\n",
      "Epoch 82/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.4755 - acc: 0.7677 - val_loss: 0.4176 - val_acc: 0.8182\n",
      "Epoch 83/100\n",
      "792/792 [==============================] - 0s 67us/step - loss: 0.4468 - acc: 0.7929 - val_loss: 0.4005 - val_acc: 0.8182\n",
      "Epoch 84/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4449 - acc: 0.7942 - val_loss: 0.4092 - val_acc: 0.8182\n",
      "Epoch 85/100\n",
      "792/792 [==============================] - 0s 66us/step - loss: 0.4516 - acc: 0.7891 - val_loss: 0.4333 - val_acc: 0.7576\n",
      "Epoch 86/100\n",
      "792/792 [==============================] - 0s 67us/step - loss: 0.4616 - acc: 0.7891 - val_loss: 0.4615 - val_acc: 0.7475\n",
      "Epoch 87/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.4643 - acc: 0.7879 - val_loss: 0.3998 - val_acc: 0.8182\n",
      "Epoch 88/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4576 - acc: 0.7891 - val_loss: 0.4052 - val_acc: 0.8283\n",
      "Epoch 89/100\n",
      "792/792 [==============================] - 0s 58us/step - loss: 0.4564 - acc: 0.7891 - val_loss: 0.4273 - val_acc: 0.7576\n",
      "Epoch 90/100\n",
      "792/792 [==============================] - 0s 61us/step - loss: 0.4832 - acc: 0.7778 - val_loss: 0.4208 - val_acc: 0.8081\n",
      "Epoch 91/100\n",
      "792/792 [==============================] - 0s 68us/step - loss: 0.4566 - acc: 0.7854 - val_loss: 0.4613 - val_acc: 0.7576\n",
      "Epoch 92/100\n",
      "792/792 [==============================] - 0s 65us/step - loss: 0.4504 - acc: 0.7917 - val_loss: 0.4626 - val_acc: 0.7576\n",
      "Epoch 93/100\n",
      "792/792 [==============================] - 0s 70us/step - loss: 0.4544 - acc: 0.7803 - val_loss: 0.4047 - val_acc: 0.8182\n",
      "Epoch 94/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.4507 - acc: 0.7841 - val_loss: 0.4130 - val_acc: 0.8081\n",
      "Epoch 95/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.4479 - acc: 0.7992 - val_loss: 0.4095 - val_acc: 0.8182\n",
      "Epoch 96/100\n",
      "792/792 [==============================] - 0s 64us/step - loss: 0.4414 - acc: 0.7980 - val_loss: 0.4274 - val_acc: 0.7576\n",
      "Epoch 97/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.4458 - acc: 0.7955 - val_loss: 0.4830 - val_acc: 0.7677\n",
      "Epoch 98/100\n",
      "792/792 [==============================] - 0s 60us/step - loss: 0.4588 - acc: 0.7841 - val_loss: 0.5114 - val_acc: 0.8283\n",
      "Epoch 99/100\n",
      "792/792 [==============================] - 0s 62us/step - loss: 0.4844 - acc: 0.7715 - val_loss: 0.5120 - val_acc: 0.7273\n",
      "Epoch 100/100\n",
      "792/792 [==============================] - 0s 70us/step - loss: 0.5075 - acc: 0.7513 - val_loss: 0.4875 - val_acc: 0.7475\n",
      "acc: 76.263%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# layers\n",
    "model.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "history = model.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_data = (test,y_test))\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"%s: %.3f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-YaWaPOKotiM",
    "outputId": "9fdf2adb-9920-4962-f297-4cc6db590606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 596 samples, validate on 295 samples\n",
      "Epoch 1/300\n",
      "596/596 [==============================] - 3s 5ms/step - loss: 0.6927 - acc: 0.5268 - val_loss: 0.6906 - val_acc: 0.6237\n",
      "Epoch 2/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.6893 - acc: 0.5956 - val_loss: 0.6874 - val_acc: 0.6237\n",
      "Epoch 3/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.6859 - acc: 0.6107 - val_loss: 0.6830 - val_acc: 0.6237\n",
      "Epoch 4/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.6816 - acc: 0.6124 - val_loss: 0.6773 - val_acc: 0.6237\n",
      "Epoch 5/300\n",
      "596/596 [==============================] - 0s 108us/step - loss: 0.6744 - acc: 0.6124 - val_loss: 0.6742 - val_acc: 0.6237\n",
      "Epoch 6/300\n",
      "596/596 [==============================] - 0s 131us/step - loss: 0.6618 - acc: 0.6124 - val_loss: 0.6801 - val_acc: 0.6237\n",
      "Epoch 7/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.6627 - acc: 0.6208 - val_loss: 0.6810 - val_acc: 0.6237\n",
      "Epoch 8/300\n",
      "596/596 [==============================] - 0s 108us/step - loss: 0.6476 - acc: 0.6191 - val_loss: 0.6881 - val_acc: 0.6305\n",
      "Epoch 9/300\n",
      "596/596 [==============================] - 0s 108us/step - loss: 0.6436 - acc: 0.6510 - val_loss: 0.7022 - val_acc: 0.3729\n",
      "Epoch 10/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.6179 - acc: 0.6728 - val_loss: 0.7083 - val_acc: 0.3763\n",
      "Epoch 11/300\n",
      "596/596 [==============================] - 0s 140us/step - loss: 0.5973 - acc: 0.6812 - val_loss: 0.7664 - val_acc: 0.3729\n",
      "Epoch 12/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.6034 - acc: 0.6711 - val_loss: 0.9219 - val_acc: 0.3763\n",
      "Epoch 13/300\n",
      "596/596 [==============================] - 0s 127us/step - loss: 0.5838 - acc: 0.6980 - val_loss: 0.9025 - val_acc: 0.3763\n",
      "Epoch 14/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.5982 - acc: 0.6913 - val_loss: 0.7267 - val_acc: 0.4712\n",
      "Epoch 15/300\n",
      "596/596 [==============================] - 0s 118us/step - loss: 0.5923 - acc: 0.6846 - val_loss: 0.6376 - val_acc: 0.6542\n",
      "Epoch 16/300\n",
      "596/596 [==============================] - 0s 116us/step - loss: 0.5730 - acc: 0.7114 - val_loss: 0.6878 - val_acc: 0.4610\n",
      "Epoch 17/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.5756 - acc: 0.7064 - val_loss: 0.6009 - val_acc: 0.7254\n",
      "Epoch 18/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.5689 - acc: 0.7248 - val_loss: 0.6037 - val_acc: 0.7017\n",
      "Epoch 19/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.5612 - acc: 0.7248 - val_loss: 0.6468 - val_acc: 0.5492\n",
      "Epoch 20/300\n",
      "596/596 [==============================] - 0s 136us/step - loss: 0.5571 - acc: 0.7265 - val_loss: 0.6968 - val_acc: 0.4237\n",
      "Epoch 21/300\n",
      "596/596 [==============================] - 0s 128us/step - loss: 0.5687 - acc: 0.7366 - val_loss: 0.6085 - val_acc: 0.7153\n",
      "Epoch 22/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5958 - acc: 0.7248 - val_loss: 0.6032 - val_acc: 0.6644\n",
      "Epoch 23/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.5483 - acc: 0.7483 - val_loss: 0.6054 - val_acc: 0.6441\n",
      "Epoch 24/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5444 - acc: 0.7315 - val_loss: 0.6279 - val_acc: 0.6000\n",
      "Epoch 25/300\n",
      "596/596 [==============================] - 0s 143us/step - loss: 0.5717 - acc: 0.7332 - val_loss: 0.5634 - val_acc: 0.7322\n",
      "Epoch 26/300\n",
      "596/596 [==============================] - 0s 128us/step - loss: 0.5572 - acc: 0.7383 - val_loss: 0.5281 - val_acc: 0.7695\n",
      "Epoch 27/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5513 - acc: 0.7232 - val_loss: 0.7438 - val_acc: 0.4237\n",
      "Epoch 28/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5770 - acc: 0.7215 - val_loss: 0.6977 - val_acc: 0.4712\n",
      "Epoch 29/300\n",
      "596/596 [==============================] - 0s 136us/step - loss: 0.5319 - acc: 0.7517 - val_loss: 0.5121 - val_acc: 0.8000\n",
      "Epoch 30/300\n",
      "596/596 [==============================] - 0s 134us/step - loss: 0.5517 - acc: 0.7517 - val_loss: 0.5298 - val_acc: 0.7254\n",
      "Epoch 31/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5520 - acc: 0.7315 - val_loss: 0.5306 - val_acc: 0.7356\n",
      "Epoch 32/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5703 - acc: 0.7366 - val_loss: 0.5132 - val_acc: 0.7932\n",
      "Epoch 33/300\n",
      "596/596 [==============================] - 0s 127us/step - loss: 0.5375 - acc: 0.7433 - val_loss: 0.5378 - val_acc: 0.7356\n",
      "Epoch 34/300\n",
      "596/596 [==============================] - 0s 134us/step - loss: 0.5584 - acc: 0.7466 - val_loss: 0.5329 - val_acc: 0.7695\n",
      "Epoch 35/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5360 - acc: 0.7517 - val_loss: 0.5507 - val_acc: 0.7492\n",
      "Epoch 36/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5241 - acc: 0.7500 - val_loss: 0.5123 - val_acc: 0.7627\n",
      "Epoch 37/300\n",
      "596/596 [==============================] - 0s 118us/step - loss: 0.5568 - acc: 0.7181 - val_loss: 0.5500 - val_acc: 0.7525\n",
      "Epoch 38/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5464 - acc: 0.7265 - val_loss: 0.5521 - val_acc: 0.7525\n",
      "Epoch 39/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.5324 - acc: 0.7601 - val_loss: 0.6565 - val_acc: 0.5864\n",
      "Epoch 40/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5366 - acc: 0.7433 - val_loss: 0.5671 - val_acc: 0.7525\n",
      "Epoch 41/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5321 - acc: 0.7433 - val_loss: 0.5949 - val_acc: 0.7288\n",
      "Epoch 42/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5559 - acc: 0.7383 - val_loss: 0.6934 - val_acc: 0.5119\n",
      "Epoch 43/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5254 - acc: 0.7433 - val_loss: 0.4986 - val_acc: 0.7831\n",
      "Epoch 44/300\n",
      "596/596 [==============================] - 0s 140us/step - loss: 0.5254 - acc: 0.7550 - val_loss: 0.4881 - val_acc: 0.7864\n",
      "Epoch 45/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5269 - acc: 0.7500 - val_loss: 0.4891 - val_acc: 0.7864\n",
      "Epoch 46/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5244 - acc: 0.7517 - val_loss: 0.5826 - val_acc: 0.7288\n",
      "Epoch 47/300\n",
      "596/596 [==============================] - 0s 124us/step - loss: 0.5206 - acc: 0.7651 - val_loss: 0.6812 - val_acc: 0.4881\n",
      "Epoch 48/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.5468 - acc: 0.7433 - val_loss: 0.5220 - val_acc: 0.7729\n",
      "Epoch 49/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5108 - acc: 0.7668 - val_loss: 0.5010 - val_acc: 0.7797\n",
      "Epoch 50/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.5380 - acc: 0.7517 - val_loss: 0.6428 - val_acc: 0.6068\n",
      "Epoch 51/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.5242 - acc: 0.7433 - val_loss: 0.8697 - val_acc: 0.4475\n",
      "Epoch 52/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5787 - acc: 0.7131 - val_loss: 0.7418 - val_acc: 0.4203\n",
      "Epoch 53/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5564 - acc: 0.7315 - val_loss: 0.5719 - val_acc: 0.7186\n",
      "Epoch 54/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5787 - acc: 0.7164 - val_loss: 0.7232 - val_acc: 0.4475\n",
      "Epoch 55/300\n",
      "596/596 [==============================] - 0s 139us/step - loss: 0.5560 - acc: 0.7232 - val_loss: 0.6606 - val_acc: 0.5119\n",
      "Epoch 56/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5609 - acc: 0.7181 - val_loss: 0.5293 - val_acc: 0.7797\n",
      "Epoch 57/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5360 - acc: 0.7349 - val_loss: 0.6176 - val_acc: 0.6203\n",
      "Epoch 58/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.5576 - acc: 0.7383 - val_loss: 0.6382 - val_acc: 0.5424\n",
      "Epoch 59/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5795 - acc: 0.7081 - val_loss: 0.6476 - val_acc: 0.6746\n",
      "Epoch 60/300\n",
      "596/596 [==============================] - 0s 119us/step - loss: 0.5392 - acc: 0.7282 - val_loss: 0.5289 - val_acc: 0.7797\n",
      "Epoch 61/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.5681 - acc: 0.7198 - val_loss: 0.6361 - val_acc: 0.5593\n",
      "Epoch 62/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.5222 - acc: 0.7601 - val_loss: 0.5028 - val_acc: 0.7831\n",
      "Epoch 63/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.5316 - acc: 0.7466 - val_loss: 0.5263 - val_acc: 0.7559\n",
      "Epoch 64/300\n",
      "596/596 [==============================] - 0s 140us/step - loss: 0.5326 - acc: 0.7567 - val_loss: 0.6768 - val_acc: 0.5593\n",
      "Epoch 65/300\n",
      "596/596 [==============================] - 0s 145us/step - loss: 0.5407 - acc: 0.7450 - val_loss: 0.5406 - val_acc: 0.7559\n",
      "Epoch 66/300\n",
      "596/596 [==============================] - 0s 120us/step - loss: 0.5487 - acc: 0.7299 - val_loss: 0.8241 - val_acc: 0.4305\n",
      "Epoch 67/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.5539 - acc: 0.7366 - val_loss: 0.7976 - val_acc: 0.4373\n",
      "Epoch 68/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.5467 - acc: 0.7349 - val_loss: 0.8573 - val_acc: 0.4271\n",
      "Epoch 69/300\n",
      "596/596 [==============================] - 0s 117us/step - loss: 0.5807 - acc: 0.6846 - val_loss: 0.5581 - val_acc: 0.6881\n",
      "Epoch 70/300\n",
      "596/596 [==============================] - 0s 134us/step - loss: 0.5536 - acc: 0.7148 - val_loss: 0.5677 - val_acc: 0.6746\n",
      "Epoch 71/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5381 - acc: 0.7517 - val_loss: 0.5479 - val_acc: 0.7661\n",
      "Epoch 72/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.5407 - acc: 0.7366 - val_loss: 0.6081 - val_acc: 0.7119\n",
      "Epoch 73/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.5383 - acc: 0.7534 - val_loss: 0.5523 - val_acc: 0.7661\n",
      "Epoch 74/300\n",
      "596/596 [==============================] - 0s 128us/step - loss: 0.5148 - acc: 0.7668 - val_loss: 0.6242 - val_acc: 0.5898\n",
      "Epoch 75/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5374 - acc: 0.7450 - val_loss: 0.5505 - val_acc: 0.7492\n",
      "Epoch 76/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.5198 - acc: 0.7567 - val_loss: 0.5905 - val_acc: 0.6780\n",
      "Epoch 77/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.5753 - acc: 0.7215 - val_loss: 0.5311 - val_acc: 0.7627\n",
      "Epoch 78/300\n",
      "596/596 [==============================] - 0s 120us/step - loss: 0.5620 - acc: 0.7215 - val_loss: 0.6205 - val_acc: 0.6746\n",
      "Epoch 79/300\n",
      "596/596 [==============================] - 0s 127us/step - loss: 0.5649 - acc: 0.7248 - val_loss: 0.6401 - val_acc: 0.5559\n",
      "Epoch 80/300\n",
      "596/596 [==============================] - 0s 144us/step - loss: 0.5240 - acc: 0.7383 - val_loss: 0.5126 - val_acc: 0.7254\n",
      "Epoch 81/300\n",
      "596/596 [==============================] - 0s 154us/step - loss: 0.5153 - acc: 0.7550 - val_loss: 0.5087 - val_acc: 0.7322\n",
      "Epoch 82/300\n",
      "596/596 [==============================] - 0s 127us/step - loss: 0.5275 - acc: 0.7668 - val_loss: 0.4782 - val_acc: 0.7661\n",
      "Epoch 83/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.5255 - acc: 0.7517 - val_loss: 0.5003 - val_acc: 0.7559\n",
      "Epoch 84/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.5324 - acc: 0.7550 - val_loss: 0.5200 - val_acc: 0.7356\n",
      "Epoch 85/300\n",
      "596/596 [==============================] - 0s 140us/step - loss: 0.5116 - acc: 0.7735 - val_loss: 0.4777 - val_acc: 0.7763\n",
      "Epoch 86/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5131 - acc: 0.7534 - val_loss: 0.4844 - val_acc: 0.7797\n",
      "Epoch 87/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5089 - acc: 0.7718 - val_loss: 0.5191 - val_acc: 0.7186\n",
      "Epoch 88/300\n",
      "596/596 [==============================] - 0s 123us/step - loss: 0.4839 - acc: 0.7836 - val_loss: 0.4896 - val_acc: 0.7864\n",
      "Epoch 89/300\n",
      "596/596 [==============================] - 0s 128us/step - loss: 0.5059 - acc: 0.7651 - val_loss: 0.4732 - val_acc: 0.8034\n",
      "Epoch 90/300\n",
      "596/596 [==============================] - 0s 143us/step - loss: 0.5053 - acc: 0.7802 - val_loss: 0.6275 - val_acc: 0.6068\n",
      "Epoch 91/300\n",
      "596/596 [==============================] - 0s 131us/step - loss: 0.4873 - acc: 0.7735 - val_loss: 0.5220 - val_acc: 0.7322\n",
      "Epoch 92/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.5362 - acc: 0.7534 - val_loss: 0.5078 - val_acc: 0.7390\n",
      "Epoch 93/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5310 - acc: 0.7416 - val_loss: 0.5174 - val_acc: 0.7593\n",
      "Epoch 94/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5566 - acc: 0.7500 - val_loss: 0.5053 - val_acc: 0.7525\n",
      "Epoch 95/300\n",
      "596/596 [==============================] - 0s 117us/step - loss: 0.5373 - acc: 0.7634 - val_loss: 0.5371 - val_acc: 0.7085\n",
      "Epoch 96/300\n",
      "596/596 [==============================] - 0s 122us/step - loss: 0.4964 - acc: 0.7819 - val_loss: 0.4885 - val_acc: 0.7966\n",
      "Epoch 97/300\n",
      "596/596 [==============================] - 0s 134us/step - loss: 0.5175 - acc: 0.7617 - val_loss: 0.4756 - val_acc: 0.7932\n",
      "Epoch 98/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.5271 - acc: 0.7483 - val_loss: 0.5169 - val_acc: 0.7424\n",
      "Epoch 99/300\n",
      "596/596 [==============================] - 0s 109us/step - loss: 0.4866 - acc: 0.7852 - val_loss: 0.5156 - val_acc: 0.7525\n",
      "Epoch 100/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5125 - acc: 0.7701 - val_loss: 0.5346 - val_acc: 0.7017\n",
      "Epoch 101/300\n",
      "596/596 [==============================] - 0s 121us/step - loss: 0.5153 - acc: 0.7752 - val_loss: 0.4867 - val_acc: 0.7831\n",
      "Epoch 102/300\n",
      "596/596 [==============================] - 0s 146us/step - loss: 0.5123 - acc: 0.7668 - val_loss: 0.5182 - val_acc: 0.7661\n",
      "Epoch 103/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.4920 - acc: 0.7735 - val_loss: 0.4834 - val_acc: 0.7864\n",
      "Epoch 104/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.4997 - acc: 0.7802 - val_loss: 0.4724 - val_acc: 0.8000\n",
      "Epoch 105/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.4925 - acc: 0.7785 - val_loss: 0.4770 - val_acc: 0.8034\n",
      "Epoch 106/300\n",
      "596/596 [==============================] - 0s 136us/step - loss: 0.5127 - acc: 0.7701 - val_loss: 0.5651 - val_acc: 0.7051\n",
      "Epoch 107/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5264 - acc: 0.7601 - val_loss: 0.5646 - val_acc: 0.7186\n",
      "Epoch 108/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.5233 - acc: 0.7584 - val_loss: 0.5221 - val_acc: 0.7492\n",
      "Epoch 109/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.5236 - acc: 0.7450 - val_loss: 0.5587 - val_acc: 0.6983\n",
      "Epoch 110/300\n",
      "596/596 [==============================] - 0s 128us/step - loss: 0.5337 - acc: 0.7466 - val_loss: 0.5848 - val_acc: 0.7186\n",
      "Epoch 111/300\n",
      "596/596 [==============================] - 0s 121us/step - loss: 0.5123 - acc: 0.7802 - val_loss: 0.5044 - val_acc: 0.7458\n",
      "Epoch 112/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5181 - acc: 0.7735 - val_loss: 0.4995 - val_acc: 0.7864\n",
      "Epoch 113/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.5272 - acc: 0.7651 - val_loss: 0.5264 - val_acc: 0.7525\n",
      "Epoch 114/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.5184 - acc: 0.7768 - val_loss: 0.5099 - val_acc: 0.7593\n",
      "Epoch 115/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.5185 - acc: 0.7534 - val_loss: 0.5750 - val_acc: 0.7153\n",
      "Epoch 116/300\n",
      "596/596 [==============================] - 0s 128us/step - loss: 0.5071 - acc: 0.7617 - val_loss: 0.5305 - val_acc: 0.7390\n",
      "Epoch 117/300\n",
      "596/596 [==============================] - 0s 138us/step - loss: 0.4824 - acc: 0.7903 - val_loss: 0.5171 - val_acc: 0.7525\n",
      "Epoch 118/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.5427 - acc: 0.7517 - val_loss: 0.5059 - val_acc: 0.7559\n",
      "Epoch 119/300\n",
      "596/596 [==============================] - 0s 117us/step - loss: 0.4924 - acc: 0.7852 - val_loss: 0.4929 - val_acc: 0.7831\n",
      "Epoch 120/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.5538 - acc: 0.7265 - val_loss: 0.7156 - val_acc: 0.5085\n",
      "Epoch 121/300\n",
      "596/596 [==============================] - 0s 116us/step - loss: 0.5088 - acc: 0.7819 - val_loss: 0.5401 - val_acc: 0.7492\n",
      "Epoch 122/300\n",
      "596/596 [==============================] - 0s 134us/step - loss: 0.5285 - acc: 0.7567 - val_loss: 0.7488 - val_acc: 0.4983\n",
      "Epoch 123/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5230 - acc: 0.7668 - val_loss: 0.4775 - val_acc: 0.7966\n",
      "Epoch 124/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.5340 - acc: 0.7466 - val_loss: 0.4948 - val_acc: 0.7729\n",
      "Epoch 125/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.5113 - acc: 0.7534 - val_loss: 0.5185 - val_acc: 0.7695\n",
      "Epoch 126/300\n",
      "596/596 [==============================] - 0s 143us/step - loss: 0.5093 - acc: 0.7869 - val_loss: 0.4818 - val_acc: 0.8034\n",
      "Epoch 127/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.5168 - acc: 0.7634 - val_loss: 0.4859 - val_acc: 0.7898\n",
      "Epoch 128/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5024 - acc: 0.7836 - val_loss: 0.4817 - val_acc: 0.7898\n",
      "Epoch 129/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.5312 - acc: 0.7500 - val_loss: 0.5737 - val_acc: 0.7085\n",
      "Epoch 130/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.5000 - acc: 0.7534 - val_loss: 0.5005 - val_acc: 0.7627\n",
      "Epoch 131/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.5014 - acc: 0.7584 - val_loss: 0.4673 - val_acc: 0.8000\n",
      "Epoch 132/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.5123 - acc: 0.7567 - val_loss: 0.4720 - val_acc: 0.7932\n",
      "Epoch 133/300\n",
      "596/596 [==============================] - 0s 141us/step - loss: 0.4899 - acc: 0.7785 - val_loss: 0.4746 - val_acc: 0.7932\n",
      "Epoch 134/300\n",
      "596/596 [==============================] - 0s 128us/step - loss: 0.5054 - acc: 0.7584 - val_loss: 0.4761 - val_acc: 0.7898\n",
      "Epoch 135/300\n",
      "596/596 [==============================] - 0s 139us/step - loss: 0.5008 - acc: 0.7584 - val_loss: 0.6262 - val_acc: 0.6068\n",
      "Epoch 136/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.5117 - acc: 0.7718 - val_loss: 0.5975 - val_acc: 0.6814\n",
      "Epoch 137/300\n",
      "596/596 [==============================] - 0s 127us/step - loss: 0.5266 - acc: 0.7584 - val_loss: 0.4836 - val_acc: 0.8034\n",
      "Epoch 138/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.5160 - acc: 0.7550 - val_loss: 0.4959 - val_acc: 0.7831\n",
      "Epoch 139/300\n",
      "596/596 [==============================] - 0s 123us/step - loss: 0.5138 - acc: 0.7852 - val_loss: 0.6332 - val_acc: 0.6712\n",
      "Epoch 140/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.5611 - acc: 0.7399 - val_loss: 0.5588 - val_acc: 0.7390\n",
      "Epoch 141/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.5381 - acc: 0.7534 - val_loss: 0.5569 - val_acc: 0.7492\n",
      "Epoch 142/300\n",
      "596/596 [==============================] - 0s 135us/step - loss: 0.5324 - acc: 0.7685 - val_loss: 0.5495 - val_acc: 0.7390\n",
      "Epoch 143/300\n",
      "596/596 [==============================] - 0s 135us/step - loss: 0.5078 - acc: 0.7651 - val_loss: 0.4792 - val_acc: 0.7932\n",
      "Epoch 144/300\n",
      "596/596 [==============================] - 0s 135us/step - loss: 0.5220 - acc: 0.7685 - val_loss: 0.4922 - val_acc: 0.7627\n",
      "Epoch 145/300\n",
      "596/596 [==============================] - 0s 140us/step - loss: 0.5046 - acc: 0.7768 - val_loss: 0.4879 - val_acc: 0.7932\n",
      "Epoch 146/300\n",
      "596/596 [==============================] - 0s 134us/step - loss: 0.5121 - acc: 0.7718 - val_loss: 0.4805 - val_acc: 0.7864\n",
      "Epoch 147/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.5103 - acc: 0.7550 - val_loss: 0.4911 - val_acc: 0.7797\n",
      "Epoch 148/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.4882 - acc: 0.7936 - val_loss: 0.4832 - val_acc: 0.7763\n",
      "Epoch 149/300\n",
      "596/596 [==============================] - 0s 137us/step - loss: 0.5128 - acc: 0.7634 - val_loss: 0.4942 - val_acc: 0.7593\n",
      "Epoch 150/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5335 - acc: 0.7265 - val_loss: 0.5483 - val_acc: 0.7492\n",
      "Epoch 151/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.4914 - acc: 0.7735 - val_loss: 0.4701 - val_acc: 0.7864\n",
      "Epoch 152/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.4887 - acc: 0.7819 - val_loss: 0.4735 - val_acc: 0.8169\n",
      "Epoch 153/300\n",
      "596/596 [==============================] - 0s 108us/step - loss: 0.5142 - acc: 0.7517 - val_loss: 0.6105 - val_acc: 0.7017\n",
      "Epoch 154/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5117 - acc: 0.7735 - val_loss: 0.6287 - val_acc: 0.6407\n",
      "Epoch 155/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.5020 - acc: 0.7768 - val_loss: 0.4702 - val_acc: 0.7864\n",
      "Epoch 156/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.5000 - acc: 0.7869 - val_loss: 0.5686 - val_acc: 0.7119\n",
      "Epoch 157/300\n",
      "596/596 [==============================] - 0s 116us/step - loss: 0.5102 - acc: 0.7819 - val_loss: 0.5461 - val_acc: 0.7085\n",
      "Epoch 158/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5076 - acc: 0.7752 - val_loss: 0.4826 - val_acc: 0.8000\n",
      "Epoch 159/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.4977 - acc: 0.7919 - val_loss: 0.6343 - val_acc: 0.6881\n",
      "Epoch 160/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5253 - acc: 0.7450 - val_loss: 0.4717 - val_acc: 0.7864\n",
      "Epoch 161/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.5007 - acc: 0.7651 - val_loss: 0.4935 - val_acc: 0.7695\n",
      "Epoch 162/300\n",
      "596/596 [==============================] - 0s 117us/step - loss: 0.5314 - acc: 0.7483 - val_loss: 0.5493 - val_acc: 0.7898\n",
      "Epoch 163/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5052 - acc: 0.7634 - val_loss: 0.4873 - val_acc: 0.7898\n",
      "Epoch 164/300\n",
      "596/596 [==============================] - 0s 144us/step - loss: 0.4798 - acc: 0.7886 - val_loss: 0.4669 - val_acc: 0.7797\n",
      "Epoch 165/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.4821 - acc: 0.8003 - val_loss: 0.4760 - val_acc: 0.7831\n",
      "Epoch 166/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.4975 - acc: 0.7903 - val_loss: 0.5346 - val_acc: 0.7254\n",
      "Epoch 167/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.4943 - acc: 0.7836 - val_loss: 0.4705 - val_acc: 0.7932\n",
      "Epoch 168/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.4969 - acc: 0.7869 - val_loss: 0.4581 - val_acc: 0.7932\n",
      "Epoch 169/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.4854 - acc: 0.7785 - val_loss: 0.5615 - val_acc: 0.7085\n",
      "Epoch 170/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5358 - acc: 0.7685 - val_loss: 0.4846 - val_acc: 0.7932\n",
      "Epoch 171/300\n",
      "596/596 [==============================] - 0s 121us/step - loss: 0.4843 - acc: 0.7768 - val_loss: 0.5654 - val_acc: 0.7220\n",
      "Epoch 172/300\n",
      "596/596 [==============================] - 0s 141us/step - loss: 0.5386 - acc: 0.7567 - val_loss: 0.5086 - val_acc: 0.7390\n",
      "Epoch 173/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.4848 - acc: 0.7869 - val_loss: 0.6111 - val_acc: 0.6746\n",
      "Epoch 174/300\n",
      "596/596 [==============================] - 0s 122us/step - loss: 0.5020 - acc: 0.7668 - val_loss: 0.4783 - val_acc: 0.7695\n",
      "Epoch 175/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.4976 - acc: 0.7701 - val_loss: 0.5656 - val_acc: 0.7051\n",
      "Epoch 176/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.4987 - acc: 0.7852 - val_loss: 0.4691 - val_acc: 0.7695\n",
      "Epoch 177/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.4830 - acc: 0.7819 - val_loss: 0.5256 - val_acc: 0.7424\n",
      "Epoch 178/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.4990 - acc: 0.7919 - val_loss: 0.5119 - val_acc: 0.7525\n",
      "Epoch 179/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.4891 - acc: 0.7953 - val_loss: 0.4937 - val_acc: 0.7763\n",
      "Epoch 180/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.4962 - acc: 0.7802 - val_loss: 0.4962 - val_acc: 0.7627\n",
      "Epoch 181/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.5184 - acc: 0.7500 - val_loss: 0.4990 - val_acc: 0.7729\n",
      "Epoch 182/300\n",
      "596/596 [==============================] - 0s 116us/step - loss: 0.4820 - acc: 0.7785 - val_loss: 0.6092 - val_acc: 0.6983\n",
      "Epoch 183/300\n",
      "596/596 [==============================] - 0s 116us/step - loss: 0.5132 - acc: 0.7718 - val_loss: 0.5137 - val_acc: 0.7424\n",
      "Epoch 184/300\n",
      "596/596 [==============================] - 0s 143us/step - loss: 0.4884 - acc: 0.7970 - val_loss: 0.5184 - val_acc: 0.7322\n",
      "Epoch 185/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.4752 - acc: 0.7886 - val_loss: 0.6165 - val_acc: 0.6746\n",
      "Epoch 186/300\n",
      "596/596 [==============================] - 0s 131us/step - loss: 0.4847 - acc: 0.7852 - val_loss: 0.4936 - val_acc: 0.7593\n",
      "Epoch 187/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5020 - acc: 0.7802 - val_loss: 0.4709 - val_acc: 0.7831\n",
      "Epoch 188/300\n",
      "596/596 [==============================] - 0s 135us/step - loss: 0.4818 - acc: 0.7886 - val_loss: 0.4579 - val_acc: 0.7729\n",
      "Epoch 189/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.4687 - acc: 0.7970 - val_loss: 0.4601 - val_acc: 0.7763\n",
      "Epoch 190/300\n",
      "596/596 [==============================] - 0s 116us/step - loss: 0.5023 - acc: 0.7768 - val_loss: 0.4719 - val_acc: 0.7932\n",
      "Epoch 191/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.4774 - acc: 0.7987 - val_loss: 0.4852 - val_acc: 0.7627\n",
      "Epoch 192/300\n",
      "596/596 [==============================] - 0s 123us/step - loss: 0.5112 - acc: 0.7752 - val_loss: 0.4594 - val_acc: 0.7864\n",
      "Epoch 193/300\n",
      "596/596 [==============================] - 0s 123us/step - loss: 0.5036 - acc: 0.7886 - val_loss: 0.4677 - val_acc: 0.7763\n",
      "Epoch 194/300\n",
      "596/596 [==============================] - 0s 109us/step - loss: 0.4650 - acc: 0.8037 - val_loss: 0.4566 - val_acc: 0.7898\n",
      "Epoch 195/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.4726 - acc: 0.8020 - val_loss: 0.4673 - val_acc: 0.7831\n",
      "Epoch 196/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5049 - acc: 0.7685 - val_loss: 0.4597 - val_acc: 0.7898\n",
      "Epoch 197/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.4625 - acc: 0.8003 - val_loss: 0.6020 - val_acc: 0.7085\n",
      "Epoch 198/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5208 - acc: 0.7617 - val_loss: 0.5166 - val_acc: 0.7424\n",
      "Epoch 199/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.5206 - acc: 0.7718 - val_loss: 0.4641 - val_acc: 0.8034\n",
      "Epoch 200/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.4859 - acc: 0.7919 - val_loss: 0.4728 - val_acc: 0.7932\n",
      "Epoch 201/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.4943 - acc: 0.7819 - val_loss: 0.4892 - val_acc: 0.7661\n",
      "Epoch 202/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.4760 - acc: 0.7903 - val_loss: 0.6000 - val_acc: 0.6847\n",
      "Epoch 203/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.4773 - acc: 0.7903 - val_loss: 0.5036 - val_acc: 0.7661\n",
      "Epoch 204/300\n",
      "596/596 [==============================] - 0s 116us/step - loss: 0.4752 - acc: 0.7936 - val_loss: 0.4731 - val_acc: 0.7898\n",
      "Epoch 205/300\n",
      "596/596 [==============================] - 0s 124us/step - loss: 0.5017 - acc: 0.7752 - val_loss: 0.6020 - val_acc: 0.7051\n",
      "Epoch 206/300\n",
      "596/596 [==============================] - 0s 136us/step - loss: 0.4928 - acc: 0.7668 - val_loss: 0.4774 - val_acc: 0.7966\n",
      "Epoch 207/300\n",
      "596/596 [==============================] - 0s 138us/step - loss: 0.4956 - acc: 0.7869 - val_loss: 0.4763 - val_acc: 0.7898\n",
      "Epoch 208/300\n",
      "596/596 [==============================] - 0s 131us/step - loss: 0.5067 - acc: 0.7836 - val_loss: 0.5499 - val_acc: 0.7458\n",
      "Epoch 209/300\n",
      "596/596 [==============================] - 0s 127us/step - loss: 0.5113 - acc: 0.7768 - val_loss: 0.4777 - val_acc: 0.7831\n",
      "Epoch 210/300\n",
      "596/596 [==============================] - 0s 127us/step - loss: 0.5077 - acc: 0.7668 - val_loss: 0.4900 - val_acc: 0.7864\n",
      "Epoch 211/300\n",
      "596/596 [==============================] - 0s 138us/step - loss: 0.5394 - acc: 0.7668 - val_loss: 0.6401 - val_acc: 0.6949\n",
      "Epoch 212/300\n",
      "596/596 [==============================] - 0s 118us/step - loss: 0.5361 - acc: 0.7634 - val_loss: 0.4921 - val_acc: 0.7932\n",
      "Epoch 213/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.5100 - acc: 0.7886 - val_loss: 0.4854 - val_acc: 0.7831\n",
      "Epoch 214/300\n",
      "596/596 [==============================] - 0s 116us/step - loss: 0.4981 - acc: 0.7735 - val_loss: 0.4614 - val_acc: 0.7797\n",
      "Epoch 215/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.4886 - acc: 0.7852 - val_loss: 0.4604 - val_acc: 0.7932\n",
      "Epoch 216/300\n",
      "596/596 [==============================] - 0s 143us/step - loss: 0.4835 - acc: 0.7987 - val_loss: 0.5327 - val_acc: 0.7356\n",
      "Epoch 217/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5037 - acc: 0.7685 - val_loss: 0.4629 - val_acc: 0.7864\n",
      "Epoch 218/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5274 - acc: 0.7634 - val_loss: 0.5080 - val_acc: 0.7492\n",
      "Epoch 219/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.4932 - acc: 0.7802 - val_loss: 0.4941 - val_acc: 0.7627\n",
      "Epoch 220/300\n",
      "596/596 [==============================] - 0s 142us/step - loss: 0.5023 - acc: 0.7752 - val_loss: 0.4725 - val_acc: 0.7966\n",
      "Epoch 221/300\n",
      "596/596 [==============================] - 0s 117us/step - loss: 0.5061 - acc: 0.7534 - val_loss: 0.5010 - val_acc: 0.7492\n",
      "Epoch 222/300\n",
      "596/596 [==============================] - 0s 131us/step - loss: 0.4787 - acc: 0.7819 - val_loss: 0.4690 - val_acc: 0.7898\n",
      "Epoch 223/300\n",
      "596/596 [==============================] - 0s 138us/step - loss: 0.4869 - acc: 0.7802 - val_loss: 0.4606 - val_acc: 0.7932\n",
      "Epoch 224/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.4922 - acc: 0.7785 - val_loss: 0.4657 - val_acc: 0.7898\n",
      "Epoch 225/300\n",
      "596/596 [==============================] - 0s 137us/step - loss: 0.5099 - acc: 0.7617 - val_loss: 0.4825 - val_acc: 0.7661\n",
      "Epoch 226/300\n",
      "596/596 [==============================] - 0s 122us/step - loss: 0.4778 - acc: 0.7936 - val_loss: 0.4800 - val_acc: 0.7898\n",
      "Epoch 227/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.4962 - acc: 0.7785 - val_loss: 0.5904 - val_acc: 0.7220\n",
      "Epoch 228/300\n",
      "596/596 [==============================] - 0s 128us/step - loss: 0.5275 - acc: 0.7735 - val_loss: 0.5111 - val_acc: 0.7458\n",
      "Epoch 229/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.5220 - acc: 0.7534 - val_loss: 0.4966 - val_acc: 0.7492\n",
      "Epoch 230/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.4871 - acc: 0.7903 - val_loss: 0.4727 - val_acc: 0.7797\n",
      "Epoch 231/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.5022 - acc: 0.7668 - val_loss: 0.4780 - val_acc: 0.7797\n",
      "Epoch 232/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.4996 - acc: 0.7601 - val_loss: 0.4817 - val_acc: 0.7627\n",
      "Epoch 233/300\n",
      "596/596 [==============================] - 0s 138us/step - loss: 0.5019 - acc: 0.7752 - val_loss: 0.4911 - val_acc: 0.7458\n",
      "Epoch 234/300\n",
      "596/596 [==============================] - 0s 146us/step - loss: 0.4800 - acc: 0.8054 - val_loss: 0.4659 - val_acc: 0.7932\n",
      "Epoch 235/300\n",
      "596/596 [==============================] - 0s 143us/step - loss: 0.4952 - acc: 0.7617 - val_loss: 0.5202 - val_acc: 0.7492\n",
      "Epoch 236/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.5003 - acc: 0.7668 - val_loss: 0.4872 - val_acc: 0.7525\n",
      "Epoch 237/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.5163 - acc: 0.7785 - val_loss: 0.5252 - val_acc: 0.7424\n",
      "Epoch 238/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.4727 - acc: 0.8020 - val_loss: 0.4673 - val_acc: 0.7932\n",
      "Epoch 239/300\n",
      "596/596 [==============================] - 0s 138us/step - loss: 0.4921 - acc: 0.7718 - val_loss: 0.4805 - val_acc: 0.7729\n",
      "Epoch 240/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.4929 - acc: 0.7919 - val_loss: 0.5525 - val_acc: 0.7492\n",
      "Epoch 241/300\n",
      "596/596 [==============================] - 0s 122us/step - loss: 0.4871 - acc: 0.7651 - val_loss: 0.4489 - val_acc: 0.7966\n",
      "Epoch 242/300\n",
      "596/596 [==============================] - 0s 124us/step - loss: 0.4837 - acc: 0.7819 - val_loss: 0.4632 - val_acc: 0.7898\n",
      "Epoch 243/300\n",
      "596/596 [==============================] - 0s 120us/step - loss: 0.4655 - acc: 0.8003 - val_loss: 0.4699 - val_acc: 0.7966\n",
      "Epoch 244/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.4884 - acc: 0.7987 - val_loss: 0.4843 - val_acc: 0.7593\n",
      "Epoch 245/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.5198 - acc: 0.7735 - val_loss: 0.4853 - val_acc: 0.7627\n",
      "Epoch 246/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.4872 - acc: 0.7886 - val_loss: 0.4714 - val_acc: 0.7831\n",
      "Epoch 247/300\n",
      "596/596 [==============================] - 0s 142us/step - loss: 0.4982 - acc: 0.7701 - val_loss: 0.4879 - val_acc: 0.7593\n",
      "Epoch 248/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.5208 - acc: 0.7617 - val_loss: 0.6083 - val_acc: 0.6712\n",
      "Epoch 249/300\n",
      "596/596 [==============================] - 0s 131us/step - loss: 0.5223 - acc: 0.7617 - val_loss: 0.7051 - val_acc: 0.5492\n",
      "Epoch 250/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.5125 - acc: 0.7668 - val_loss: 0.4973 - val_acc: 0.7661\n",
      "Epoch 251/300\n",
      "596/596 [==============================] - 0s 125us/step - loss: 0.5082 - acc: 0.7735 - val_loss: 0.4805 - val_acc: 0.7729\n",
      "Epoch 252/300\n",
      "596/596 [==============================] - 0s 131us/step - loss: 0.4986 - acc: 0.7651 - val_loss: 0.8136 - val_acc: 0.5051\n",
      "Epoch 253/300\n",
      "596/596 [==============================] - 0s 116us/step - loss: 0.5441 - acc: 0.7701 - val_loss: 0.4738 - val_acc: 0.7831\n",
      "Epoch 254/300\n",
      "596/596 [==============================] - 0s 124us/step - loss: 0.4853 - acc: 0.7768 - val_loss: 0.4851 - val_acc: 0.7763\n",
      "Epoch 255/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.4866 - acc: 0.7802 - val_loss: 0.4608 - val_acc: 0.7797\n",
      "Epoch 256/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.5171 - acc: 0.7651 - val_loss: 0.5145 - val_acc: 0.7288\n",
      "Epoch 257/300\n",
      "596/596 [==============================] - 0s 121us/step - loss: 0.4875 - acc: 0.7785 - val_loss: 0.5781 - val_acc: 0.6305\n",
      "Epoch 258/300\n",
      "596/596 [==============================] - 0s 128us/step - loss: 0.5065 - acc: 0.7752 - val_loss: 0.4867 - val_acc: 0.7627\n",
      "Epoch 259/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.4764 - acc: 0.7936 - val_loss: 0.4692 - val_acc: 0.7729\n",
      "Epoch 260/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.4701 - acc: 0.7987 - val_loss: 0.4566 - val_acc: 0.7932\n",
      "Epoch 261/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.4882 - acc: 0.7802 - val_loss: 0.5157 - val_acc: 0.7186\n",
      "Epoch 262/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.5021 - acc: 0.7903 - val_loss: 0.4572 - val_acc: 0.7898\n",
      "Epoch 263/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.4995 - acc: 0.7785 - val_loss: 0.4593 - val_acc: 0.7661\n",
      "Epoch 264/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.4934 - acc: 0.7819 - val_loss: 0.5470 - val_acc: 0.7051\n",
      "Epoch 265/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.5046 - acc: 0.7802 - val_loss: 0.4551 - val_acc: 0.7898\n",
      "Epoch 266/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.5101 - acc: 0.7617 - val_loss: 0.4564 - val_acc: 0.7966\n",
      "Epoch 267/300\n",
      "596/596 [==============================] - 0s 117us/step - loss: 0.4817 - acc: 0.7886 - val_loss: 0.5206 - val_acc: 0.7424\n",
      "Epoch 268/300\n",
      "596/596 [==============================] - 0s 109us/step - loss: 0.4864 - acc: 0.7802 - val_loss: 0.4533 - val_acc: 0.7864\n",
      "Epoch 269/300\n",
      "596/596 [==============================] - 0s 107us/step - loss: 0.4915 - acc: 0.7685 - val_loss: 0.4516 - val_acc: 0.7831\n",
      "Epoch 270/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.5180 - acc: 0.7768 - val_loss: 0.4553 - val_acc: 0.7763\n",
      "Epoch 271/300\n",
      "596/596 [==============================] - 0s 136us/step - loss: 0.4969 - acc: 0.7819 - val_loss: 0.5733 - val_acc: 0.6881\n",
      "Epoch 272/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.4806 - acc: 0.7852 - val_loss: 0.4979 - val_acc: 0.7492\n",
      "Epoch 273/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.5038 - acc: 0.7735 - val_loss: 0.4512 - val_acc: 0.7932\n",
      "Epoch 274/300\n",
      "596/596 [==============================] - 0s 135us/step - loss: 0.5172 - acc: 0.7634 - val_loss: 0.4796 - val_acc: 0.7661\n",
      "Epoch 275/300\n",
      "596/596 [==============================] - 0s 130us/step - loss: 0.5112 - acc: 0.7701 - val_loss: 0.4569 - val_acc: 0.7932\n",
      "Epoch 276/300\n",
      "596/596 [==============================] - 0s 150us/step - loss: 0.4871 - acc: 0.7718 - val_loss: 0.4680 - val_acc: 0.7831\n",
      "Epoch 277/300\n",
      "596/596 [==============================] - 0s 132us/step - loss: 0.4834 - acc: 0.7987 - val_loss: 0.4766 - val_acc: 0.7593\n",
      "Epoch 278/300\n",
      "596/596 [==============================] - 0s 122us/step - loss: 0.5007 - acc: 0.7735 - val_loss: 0.5212 - val_acc: 0.7390\n",
      "Epoch 279/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.4836 - acc: 0.7836 - val_loss: 0.4581 - val_acc: 0.7898\n",
      "Epoch 280/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.5111 - acc: 0.7752 - val_loss: 0.4765 - val_acc: 0.7898\n",
      "Epoch 281/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.4709 - acc: 0.7987 - val_loss: 0.4892 - val_acc: 0.7695\n",
      "Epoch 282/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.4598 - acc: 0.7919 - val_loss: 0.4538 - val_acc: 0.7932\n",
      "Epoch 283/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.4881 - acc: 0.7752 - val_loss: 0.5061 - val_acc: 0.7458\n",
      "Epoch 284/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.4924 - acc: 0.7752 - val_loss: 0.4757 - val_acc: 0.7763\n",
      "Epoch 285/300\n",
      "596/596 [==============================] - 0s 113us/step - loss: 0.4743 - acc: 0.7886 - val_loss: 0.4781 - val_acc: 0.7831\n",
      "Epoch 286/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.4944 - acc: 0.7685 - val_loss: 0.4803 - val_acc: 0.7559\n",
      "Epoch 287/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.4867 - acc: 0.7987 - val_loss: 0.4585 - val_acc: 0.7932\n",
      "Epoch 288/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.4882 - acc: 0.7936 - val_loss: 0.4620 - val_acc: 0.7966\n",
      "Epoch 289/300\n",
      "596/596 [==============================] - 0s 112us/step - loss: 0.5060 - acc: 0.7718 - val_loss: 0.4577 - val_acc: 0.8068\n",
      "Epoch 290/300\n",
      "596/596 [==============================] - 0s 111us/step - loss: 0.4737 - acc: 0.7953 - val_loss: 0.5331 - val_acc: 0.7729\n",
      "Epoch 291/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.4963 - acc: 0.7668 - val_loss: 0.5095 - val_acc: 0.7797\n",
      "Epoch 292/300\n",
      "596/596 [==============================] - 0s 110us/step - loss: 0.4936 - acc: 0.7919 - val_loss: 0.4856 - val_acc: 0.7763\n",
      "Epoch 293/300\n",
      "596/596 [==============================] - 0s 114us/step - loss: 0.4817 - acc: 0.7953 - val_loss: 0.4622 - val_acc: 0.7831\n",
      "Epoch 294/300\n",
      "596/596 [==============================] - 0s 136us/step - loss: 0.4779 - acc: 0.7953 - val_loss: 0.4592 - val_acc: 0.7898\n",
      "Epoch 295/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.4856 - acc: 0.7869 - val_loss: 0.4842 - val_acc: 0.7831\n",
      "Epoch 296/300\n",
      "596/596 [==============================] - 0s 124us/step - loss: 0.4980 - acc: 0.7601 - val_loss: 0.5609 - val_acc: 0.7288\n",
      "Epoch 297/300\n",
      "596/596 [==============================] - 0s 129us/step - loss: 0.4746 - acc: 0.7987 - val_loss: 0.4841 - val_acc: 0.7627\n",
      "Epoch 298/300\n",
      "596/596 [==============================] - 0s 133us/step - loss: 0.5221 - acc: 0.7450 - val_loss: 0.5200 - val_acc: 0.7254\n",
      "Epoch 299/300\n",
      "596/596 [==============================] - 0s 115us/step - loss: 0.4927 - acc: 0.7852 - val_loss: 0.4605 - val_acc: 0.8000\n",
      "Epoch 300/300\n",
      "596/596 [==============================] - 0s 126us/step - loss: 0.4866 - acc: 0.7802 - val_loss: 0.4710 - val_acc: 0.7831\n",
      "acc: 82.047%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# layers\n",
    "model.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "history = model.fit(X_train, y_train, batch_size = 32, epochs = 150, validation_data = (X_test,y_test))\n",
    "\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"%s: %.3f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "27_aMSwVBV8E",
    "outputId": "1f56833e-ba28-4aa8-8462-2ab01853cbbd"
   },
   "source": [
    "#### Results:\n",
    "\n",
    "|     Metric     |Support Vector M/c | Neural-Network  |\n",
    "| :------------: | :---------------: | :-------------: | \n",
    "| Accuracy Score |           0.7980  |        0.7621   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DfroqkSVBnDf"
   },
   "source": [
    "**Increased the number of epochs training and added extra dropout and Batch norm layers to compete with SVMs,i.e, in order to increase the performance**\n",
    "\n",
    "|     Metric     |Support Vector M/c | Neural-Network  |\n",
    "| :------------: | :---------------: | :-------------: | \n",
    "| Accuracy Score |           0.7980  |        0.8204   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SVM vs 3-NN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
